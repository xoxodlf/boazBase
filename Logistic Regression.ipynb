{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "seed = 1215\n",
    "X, y = sklearn.datasets.make_classification(n_samples=1000, n_features=2, n_classes=2, n_informative = 2, n_redundant = 0, n_repeated = 0,random_state = seed)\n",
    "\n",
    "X_train = X[:800]\n",
    "X_train = X_train[:,0]\n",
    "X_test = X[800:]\n",
    "X_test = X_test[:,0]\n",
    "y_train = y[:800]\n",
    "y_test = y[800:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 다음과 같은 산점도를 그려주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.legend([\"train\", \"test\"])\n",
    "# Your Code Here\n",
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 가중치가 1일 때 loss를 계산해보세요. h(x) = 1/1+e^-x 입니다\n",
    "![logisticregression](https://i.stack.imgur.com/XbU4S.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x, mytheta):\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticLoss(X, y, mytheta):\n",
    "    error0 = 0\n",
    "    error1 = 0\n",
    "# Your Code Here(for문을 이용해 짜보세요)\n",
    "# math.log는 0에 가까우면 오류가 뜹니다(계산이 안됩니다).\n",
    "# try, except를 이용해 sigmoid와 같이 log값을 700 또는 -700으로 설정해주세요\n",
    "    for i, j in zip(X, y):\n",
    "    return -(error0+error1)/len(X)\n",
    "\n",
    "# seed가 같을 경우 LogisticLoss값은 같아야 합니다.\n",
    "print(LogisticLoss(X_train, y_train, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Gradient Descent 기반으로 주어진 loss를 최소화하는 weight를 찾아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "learningrate = 0.01\n",
    "m = y_train.size\n",
    "\n",
    "# 초기값은 자유입니다\n",
    "def Gradientdescent(X, y, theta_start):\n",
    "    m= X.size\n",
    "    theta = theta_start\n",
    "    for meaningless in range(iterations):\n",
    "        # Your Code Here\n",
    "        # Cross Entropy Loss를 theta에 대해 미분하면 됩니다.\n",
    "        # Cross Entropy Loss 미분은 아래의 동영상을 참고하세요\n",
    "        # https://www.youtube.com/watch?v=mLth3-4yn4Q \n",
    "        ###\n",
    "        theta -= learningrate*gradient\n",
    "    LogisticLoss(X_test, y_test, theta)\n",
    "    return print('Optimal \"a\" is:', round(theta,3), '\\n','Logistic Loss :', round(LogisticLoss(X_test, y_test, theta),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradientdescent(X_train,y_train,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Loss의 변화를 plot으로 나타내보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "learningrate = 0.1\n",
    "m = y_train.size\n",
    "\n",
    "# 초기값은 자유입니다\n",
    "def Gradientdescent(X, y, theta_start):\n",
    "    m= X.size\n",
    "    theta = theta_start\n",
    "    loss = []\n",
    "    for meaningless in range(iterations):\n",
    "        #Your Code Here\n",
    "        ###\n",
    "        ###\n",
    "        ###\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100으로 하면 Convergence가 좀 더 잘 보입니다.\n",
    "Loss = Gradientdescent(X_train,y_train,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.title(\"Convergence of Cost Function\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlim([0,1000])\n",
    "plt.ylim([0,5])\n",
    "#Your Code Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
